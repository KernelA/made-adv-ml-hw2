{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn import pipeline\n",
    "from sklearn import linear_model\n",
    "from scipy import sparse, stats\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rating_model import TeamResults\n",
    "from rating_model import PICKLE_PROTOCOL\n",
    "from rating_model import EMRatingModel, get_player_skills, estimate_rank\n",
    "from utils import load_pickle, dump_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tours_datapath = pathlib.Path(\"data\", \"pickle_data\", \"tournaments-dt.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tours = pd.read_pickle(str(tours_datapath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_datapath = pathlib.Path(\"data\", \"pickle_data\", \"players-dt.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_info = pd.read_pickle(players_datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_res_datapath = pathlib.Path(\n",
    "    \"data\", \"team_res\", \"train_team_results.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_res = load_pickle(team_res_datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_unknown_team_players = 0\n",
    "total_unknown_answers = 0\n",
    "for tour_id in team_res.tours:\n",
    "    for team_id in team_res[tour_id]:\n",
    "        team = team_res[tour_id][team_id]\n",
    "        if not team.members:\n",
    "            total_unknown_team_players += 1\n",
    "        if not team.mask:\n",
    "            total_unknown_answers += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество команд без состава команды: \n",
      "109\n",
      "Количество команд с неизвестными повопроснами результатами: \n",
      "173\n"
     ]
    }
   ],
   "source": [
    "print(\"Количество команд без состава команды: \", total_unknown_team_players,\n",
    "      \"Количество команд с неизвестными повопроснами результатами: \", total_unknown_answers, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1105 entries, 4628 to 6485\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype              \n",
      "---  ------        --------------  -----              \n",
      " 0   name          1105 non-null   object             \n",
      " 1   dateStart     1105 non-null   datetime64[ns, UTC]\n",
      " 2   dateEnd       1105 non-null   datetime64[ns, UTC]\n",
      " 3   type          1105 non-null   object             \n",
      " 4   season        1015 non-null   object             \n",
      " 5   orgcommittee  1105 non-null   object             \n",
      " 6   synchData     669 non-null    object             \n",
      " 7   questionQty   1105 non-null   object             \n",
      "dtypes: datetime64[ns, UTC](2), object(6)\n",
      "memory usage: 77.7+ KB\n"
     ]
    }
   ],
   "source": [
    "tours.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_dump = pathlib.Path(\"dump\", \"players.pickle\")\n",
    "players_dump.parent.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "force_get_players = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "players = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not players_dump.exists() or force_get_players:\n",
    "    players = team_res.to_player_dataframe(filter_by_mask=True)\n",
    "    optimize_dataframe_numeric_dtypes(players)\n",
    "    dump_pickle(players_dump, players)\n",
    "else:\n",
    "    players = load_pickle(players_dump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert players.index.is_monotonic_increasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17949880 entries, 0 to 17949879\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Dtype\n",
      "---  ------           -----\n",
      " 0   tour_id          int16\n",
      " 1   team_id          int32\n",
      " 2   player_id        int32\n",
      " 3   answer_id        int16\n",
      " 4   is_right_answer  bool \n",
      "dtypes: bool(1), int16(2), int32(2)\n",
      "memory usage: 222.5 MB\n"
     ]
    }
   ],
   "source": [
    "players.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tour_id</th>\n",
       "      <th>team_id</th>\n",
       "      <th>player_id</th>\n",
       "      <th>answer_id</th>\n",
       "      <th>is_right_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4772</td>\n",
       "      <td>45556</td>\n",
       "      <td>6212</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4772</td>\n",
       "      <td>45556</td>\n",
       "      <td>6212</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4772</td>\n",
       "      <td>45556</td>\n",
       "      <td>6212</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4772</td>\n",
       "      <td>45556</td>\n",
       "      <td>6212</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4772</td>\n",
       "      <td>45556</td>\n",
       "      <td>6212</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tour_id  team_id  player_id  answer_id  is_right_answer\n",
       "0     4772    45556       6212          0             True\n",
       "1     4772    45556       6212          1             True\n",
       "2     4772    45556       6212          2             True\n",
       "3     4772    45556       6212          3             True\n",
       "4     4772    45556       6212          4             True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = players[\"is_right_answer\"].astype(np.int8).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# players[\"tour_team_id\"] = (players[\"tour_id\"].astype(str) + \" \" + players[\"team_id\"].astype(str)).factorize()[0]\n",
    "# player_indices_in_team_by_round = []\n",
    "\n",
    "# for group, data in players.groupby(\"tour_team_id\"):\n",
    "#     player_indices_in_team_by_round.append(data.index.to_list())\n",
    "\n",
    "# max_length = len(max(player_indices_in_team_by_round, key=len))\n",
    "# # pad_index это фейковый индекс и нужен только для того чтобы использовать функцию np.take\n",
    "# # Значение по этому индексу всегда равно 0\n",
    "# PAD_INDEX = len(target)\n",
    "# for i in range(len(player_indices_in_team_by_round)):\n",
    "#     indices = player_indices_in_team_by_round[i]\n",
    "#     if len(indices) < max_length:\n",
    "#         zeroing_mask[indices] = 1\n",
    "#         player_indices_in_team_by_round[i].extend(repeat(PAD_INDEX, max_length - len(indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# players.drop(\"tour_team_id\", axis=\"columns\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# player_indices_in_team_by_round = np.array(player_indices_in_team_by_round)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Построение логистической регрессии для ранжирования игроков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    0.568645\n",
       "True     0.431355\n",
       "Name: is_right_answer, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players[\"is_right_answer\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dtype = np.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "skils_encoder = preprocessing.OneHotEncoder(dtype=feature_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "skils_features = skils_encoder.fit_transform(\n",
    "    players[\"player_id\"].to_numpy().reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "questione_complex_encoder = preprocessing.OneHotEncoder(dtype=feature_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_complex = questione_complex_encoder.fit_transform(\n",
    "    players[\"answer_id\"].to_numpy().reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = sparse.hstack((skils_features, questions_complex))\n",
    "features = sparse.csr_matrix(features)\n",
    "del skils_features\n",
    "del questions_complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<17949880x91104 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 35899760 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_model_filepath = pathlib.Path(\"model\", \"log-reg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_model_filepath.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "force_train = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dump = dump_model_filepath / \"log-reg.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not force_train and model_dump.exists():\n",
    "    regression = load_pickle(model_dump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if regression is None:\n",
    "    regression = linear_model.LogisticRegression(\n",
    "        penalty=\"none\", verbose=2, max_iter=200)\n",
    "    regression.fit(features, target)\n",
    "    dump_pickle(model_dump, regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_rating(skill_encoder, coefs) -> pd.DataFrame:\n",
    "#     rows = []\n",
    "#     all_players_ids = skill_encoder.categories_[0]\n",
    "#     for player_id in all_players_ids:\n",
    "#         rows.append({\"player_id\": player_id, \"skill\": coefs[np.where(\n",
    "#             all_players_ids == player_id)[0][0]]})\n",
    "#     return pd.DataFrame.from_records(rows, index=\"player_id\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "player_ratings = get_player_skills(skils_encoder, regression.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_ratings.sort_values(\"skill\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skill</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>player_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27403</th>\n",
       "      <td>4.053972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4270</th>\n",
       "      <td>3.904938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28751</th>\n",
       "      <td>3.768449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30260</th>\n",
       "      <td>3.658079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30152</th>\n",
       "      <td>3.650698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              skill\n",
       "player_id          \n",
       "27403      4.053972\n",
       "4270       3.904938\n",
       "28751      3.768449\n",
       "30260      3.658079\n",
       "30152      3.650698"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player_ratings.nlargest(5, \"skill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка результатов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для сравнение команд воспользуемся простым правилом. Для каждой команды в турнире возьмём игроков в отсортированном по убыванию силе игроков и отсортируем команды в лексикографическом порядке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_team_res_datapath = pathlib.Path(\n",
    "    \"data\", \"team_res\", \"test_team_results.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(test_team_res_datapath, \"rb\") as dump_file:\n",
    "    team_res_test = pickle.load(dump_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_team_ratings = team_res_test.to_team_rating_by_tour()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_team_ratings.dropna(axis=\"index\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 21914 entries, 0 to 22430\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   tour_id      21914 non-null  int64  \n",
      " 1   members      21914 non-null  object \n",
      " 2   team_id      21914 non-null  int64  \n",
      " 3   tour_rating  21914 non-null  float64\n",
      "dtypes: float64(1), int64(2), object(1)\n",
      "memory usage: 856.0+ KB\n"
     ]
    }
   ],
   "source": [
    "test_team_ratings.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_team_ratings.sort_values([\"tour_id\", \"tour_rating\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tour_id</th>\n",
       "      <th>members</th>\n",
       "      <th>team_id</th>\n",
       "      <th>tour_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4957</td>\n",
       "      <td>(30152, 30270, 27822, 28751, 27403, 4270)</td>\n",
       "      <td>49804</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4957</td>\n",
       "      <td>(34936, 40877, 25177, 113703, 33792, 107161)</td>\n",
       "      <td>4109</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4957</td>\n",
       "      <td>(33620, 21346, 13857, 46339, 37836, 19632)</td>\n",
       "      <td>3875</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4957</td>\n",
       "      <td>(32901, 28689, 19541, 13689, 9801, 18194)</td>\n",
       "      <td>77418</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4957</td>\n",
       "      <td>(6482, 34846, 36120, 32458, 25882, 30475)</td>\n",
       "      <td>2</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tour_id                                       members  team_id  tour_rating\n",
       "0     4957     (30152, 30270, 27822, 28751, 27403, 4270)    49804          1.0\n",
       "1     4957  (34936, 40877, 25177, 113703, 33792, 107161)     4109          2.0\n",
       "2     4957    (33620, 21346, 13857, 46339, 37836, 19632)     3875          3.0\n",
       "3     4957     (32901, 28689, 19541, 13689, 9801, 18194)    77418          4.0\n",
       "4     4957     (6482, 34846, 36120, 32458, 25882, 30475)        2          5.5"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_team_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def player2ratings(players_id, player_ratings):\n",
    "#     ratings = []\n",
    "#     for player_id in players_id:\n",
    "#         try:\n",
    "#             ratings.append(player_ratings.loc[player_id, \"skill\"])\n",
    "#         except KeyError:\n",
    "#             pass\n",
    "#     ratings.sort(reverse=True)\n",
    "#     return tuple(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rank_teams(teams, player_skills):\n",
    "#     ranking_teams = teams.copy()\n",
    "#     ranking_teams[\"player_skils\"] = ranking_teams[\"members\"].apply(\n",
    "#         lambda x: player2ratings(x, player_skills))\n",
    "#     ranking_teams.sort_values(\"player_skils\", ascending=False, inplace=True)\n",
    "#     ranking_teams.drop(\"player_skils\", axis=\"columns\", inplace=True)\n",
    "#     return ranking_teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def estimate_rank(team_res, player_ratings):\n",
    "#     kendall_values = []\n",
    "#     for tour_id, teams in team_res.groupby(\"tour_id\"):\n",
    "#         new_teams = teams[[\"members\", \"tour_rating\"]].copy()\n",
    "#         new_teams.reset_index(inplace=True)\n",
    "#         original_order = new_teams.index.to_numpy()\n",
    "#         new_teams = rank_teams(new_teams, player_ratings)\n",
    "#         rank_order = new_teams.index.to_numpy()\n",
    "#         kendall_values.append(stats.kendalltau(original_order, rank_order)[0])\n",
    "#     return np.nanmean(kendall_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Коэффициент ранговой корреляции Кендалла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kendall': 0.5752683352089869, 'spearman': 0.7425997814841886}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_rank(test_team_ratings, player_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "del player_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EM алгоритм"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмртрим ответы команды на вопросы. Если команда $t$ ответила на вопрос $q$, то это означает, что хотя бы один игрок ответил на вопрос. Если команда не ответила на вопрос, то это означает, что ни один игрок также не оветил на вопрос.\n",
    "\n",
    "Таким образом введём скрытые переменные: $h_{i,q}$- игорок под номером $i$ ответил на вопрос $q$. Они связаны с $x_{t,q}$ следующим соотношением:\n",
    "$$\n",
    "x_{t,q} = \n",
    "\\begin{cases}\n",
    "0, \\text{ то } h_{i,q} = 0 \\text{ для всех игроков в команде } t,\\\\\n",
    "1, h_{i,q}=1 \\text{ для хотя бы одного игрока в команде } t. \n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Тогда веротяность $p\\left(h_{i,q} \\vert s_i, c_q\\right) \\sim \\sigma\\left(b + s_i + c_q\\right), s_i-$ сила игрока $i$, $c_q-$ сложность вопроса, $b \\in \\mathbb{R}-$ глобальное смещение. Условную веротяность будем моделировать с помощью сигмоиды."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим итерация EM-алгоритма для $m \\geq 0$.\n",
    "\n",
    "## E-шаг\n",
    "\n",
    "$$\n",
    "\\mathrm{M} \\left[ h^{(m+1)}_{i,q} \\right] = \n",
    "\\begin{cases}\n",
    "0, x_{t,q} = 0,\\\\\n",
    "p\\left( h^{(m)}_{i,q} = 1 \\vert \\exists j \\in t, h^{(m)}_{j,k} = 1\\right) =\n",
    "\\dfrac{\\sigma \\left(b^{(m)} + s^{(m)}_i + c^{(m)}_q\\right)}{1-\\prod\\limits_{k \\in t} \\left(1 - \\sigma\\left(b^{(m)} + s^{(m)}_k + c^{(m)}_q\\right)\\right)}, \\text{ если } x_{t,q} = 1.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "## М-шаг\n",
    "\n",
    "Происходит обучение обучение логистичексой регрессии при известных $\\mathrm{M} \\left[ h^{(m+1)}_{i,q} \\right]$ и уточнение параметров:\n",
    "$$\n",
    "\\mathrm{M} \\left[ h^{(m+1)}_{i,q} \\right] \\sim \\sigma\\left(b^{(m+1)} + s^{(m+1)}_k + c^{(m+1)}_q\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "Пусть параметры модели образуют составляют вектор $w = \\left(s_1,s_2,\\ldots,s_P, c_1, c_2, \\ldots, c_A, b \\right)^T,$ где $P-$ общее число игроков, $A-$ общее число вопросов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sigmoid(x):\n",
    "#     return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def update_hidden_values(hidden_variables, indices_player_in_one_team_by_round, predicted_proba, pad_index):\n",
    "#     predicted_proba_by_groups = np.take(predicted_proba, indices_player_in_one_team_by_round)\n",
    "#     predicted_proba_by_groups /= (1 - np.prod(1 - predicted_proba_by_groups, axis=1).reshape(-1, 1))\n",
    "\n",
    "#     for i, index in enumerate(indices_player_in_one_team_by_round):\n",
    "#         not_fake_mask = index != pad_index\n",
    "#         not_fake_indices = index[not_fake_mask]\n",
    "#         hidden_variables[not_fake_indices] = predicted_proba_by_groups[i, not_fake_mask]\n",
    "\n",
    "#     np.nan_to_num(hidden_variables, copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def expectation(hidden_variables, target, indices_player_in_one_team_by_round, features, w, b, pad_index):\n",
    "#     hidden_variables.fill(0)\n",
    "#     predicted_proba = (features @ w).astype(np.float32)\n",
    "#     predicted_proba += b\n",
    "#     # Add fake value for vectorizing idexing operations\n",
    "#     predicted_proba = np.append(predicted_proba, 0)\n",
    "#     update_hidden_values(hidden_variables, indices_player_in_one_team_by_round, predicted_proba, pad_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden_variables = np.zeros_like(target, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expectation(hidden_variables, target, player_indices_in_team_by_round, features, regression.coef_[0].astype(np.float32), regression.intercept_.astype(np.float32), PAD_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "coo_features = features.tocoo(copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<17949880x91104 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 35899760 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coo_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-01 02:04:29,919 INFO em_algo __init__ Will train logistic regression on cuda\n"
     ]
    }
   ],
   "source": [
    "em_model = EMRatingModel(em_num_iter=4, lr=1e-2,\n",
    "                         log_reg_num_iter=20, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-01 02:04:39,717 INFO em_algo _build_player_team_round_indices Build indices masks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 86964/86964 [00:09<00:00, 9609.69it/s]\n",
      "M step:   0%|                                                                                                                        | 0/4 [00:00<?, ?it/s]\n",
      "Train logistic regression:   0%|                                                                                                    | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Train logistic regression:   0%|                                                                          | 0/20 [00:00<?, ?it/s, Loss=0.693, mae_loss=0.5]\u001b[A\n",
      "Train logistic regression:   5%|███▎                                                              | 1/20 [00:00<00:16,  1.14it/s, Loss=0.693, mae_loss=0.5]\u001b[A\n",
      "Train logistic regression:   5%|███▏                                                            | 1/20 [00:01<00:16,  1.14it/s, Loss=0.689, mae_loss=0.498]\u001b[A\n",
      "Train logistic regression:  10%|██████▍                                                         | 2/20 [00:01<00:15,  1.15it/s, Loss=0.689, mae_loss=0.498]\u001b[A\n",
      "Train logistic regression:  10%|██████▍                                                         | 2/20 [00:02<00:15,  1.15it/s, Loss=0.685, mae_loss=0.496]\u001b[A\n",
      "Train logistic regression:  15%|█████████▌                                                      | 3/20 [00:02<00:14,  1.14it/s, Loss=0.685, mae_loss=0.496]\u001b[A\n",
      "Train logistic regression:  15%|█████████▌                                                      | 3/20 [00:03<00:14,  1.14it/s, Loss=0.681, mae_loss=0.494]\u001b[A\n",
      "Train logistic regression:  20%|████████████▊                                                   | 4/20 [00:03<00:14,  1.14it/s, Loss=0.681, mae_loss=0.494]\u001b[A\n",
      "Train logistic regression:  20%|████████████▊                                                   | 4/20 [00:04<00:14,  1.14it/s, Loss=0.678, mae_loss=0.492]\u001b[A\n",
      "Train logistic regression:  25%|████████████████                                                | 5/20 [00:04<00:13,  1.14it/s, Loss=0.678, mae_loss=0.492]\u001b[A\n",
      "Train logistic regression:  25%|████████████████▎                                                | 5/20 [00:05<00:13,  1.14it/s, Loss=0.674, mae_loss=0.49]\u001b[A\n",
      "Train logistic regression:  30%|███████████████████▌                                             | 6/20 [00:05<00:12,  1.14it/s, Loss=0.674, mae_loss=0.49]\u001b[A\n",
      "Train logistic regression:  30%|███████████████████▏                                            | 6/20 [00:06<00:12,  1.14it/s, Loss=0.671, mae_loss=0.488]\u001b[A\n",
      "Train logistic regression:  35%|██████████████████████▍                                         | 7/20 [00:06<00:11,  1.14it/s, Loss=0.671, mae_loss=0.488]\u001b[A\n",
      "Train logistic regression:  35%|██████████████████████▍                                         | 7/20 [00:07<00:11,  1.14it/s, Loss=0.667, mae_loss=0.486]\u001b[A\n",
      "Train logistic regression:  40%|█████████████████████████▌                                      | 8/20 [00:07<00:10,  1.13it/s, Loss=0.667, mae_loss=0.486]\u001b[A\n",
      "Train logistic regression:  40%|█████████████████████████▌                                      | 8/20 [00:07<00:10,  1.13it/s, Loss=0.664, mae_loss=0.484]\u001b[A\n",
      "Train logistic regression:  45%|████████████████████████████▊                                   | 9/20 [00:07<00:09,  1.14it/s, Loss=0.664, mae_loss=0.484]\u001b[A\n",
      "Train logistic regression:  45%|████████████████████████████▊                                   | 9/20 [00:08<00:09,  1.14it/s, Loss=0.661, mae_loss=0.482]\u001b[A\n",
      "Train logistic regression:  50%|███████████████████████████████▌                               | 10/20 [00:08<00:08,  1.13it/s, Loss=0.661, mae_loss=0.482]\u001b[A\n",
      "Train logistic regression:  50%|████████████████████████████████                                | 10/20 [00:09<00:08,  1.13it/s, Loss=0.658, mae_loss=0.48]\u001b[A\n",
      "Train logistic regression:  55%|███████████████████████████████████▏                            | 11/20 [00:09<00:07,  1.13it/s, Loss=0.658, mae_loss=0.48]\u001b[A\n",
      "Train logistic regression:  55%|██████████████████████████████████▋                            | 11/20 [00:10<00:07,  1.13it/s, Loss=0.654, mae_loss=0.478]\u001b[A\n",
      "Train logistic regression:  60%|█████████████████████████████████████▊                         | 12/20 [00:10<00:07,  1.13it/s, Loss=0.654, mae_loss=0.478]\u001b[A\n",
      "Train logistic regression:  60%|█████████████████████████████████████▊                         | 12/20 [00:11<00:07,  1.13it/s, Loss=0.652, mae_loss=0.476]\u001b[A\n",
      "Train logistic regression:  65%|████████████████████████████████████████▉                      | 13/20 [00:11<00:06,  1.12it/s, Loss=0.652, mae_loss=0.476]\u001b[A\n",
      "Train logistic regression:  65%|████████████████████████████████████████▉                      | 13/20 [00:12<00:06,  1.12it/s, Loss=0.649, mae_loss=0.474]\u001b[A\n",
      "Train logistic regression:  70%|████████████████████████████████████████████                   | 14/20 [00:12<00:05,  1.12it/s, Loss=0.649, mae_loss=0.474]\u001b[A\n",
      "Train logistic regression:  70%|████████████████████████████████████████████                   | 14/20 [00:13<00:05,  1.12it/s, Loss=0.646, mae_loss=0.473]\u001b[A\n",
      "Train logistic regression:  75%|███████████████████████████████████████████████▎               | 15/20 [00:13<00:04,  1.13it/s, Loss=0.646, mae_loss=0.473]\u001b[A\n",
      "Train logistic regression:  75%|███████████████████████████████████████████████▎               | 15/20 [00:14<00:04,  1.13it/s, Loss=0.643, mae_loss=0.471]\u001b[A\n",
      "Train logistic regression:  80%|██████████████████████████████████████████████████▍            | 16/20 [00:14<00:03,  1.13it/s, Loss=0.643, mae_loss=0.471]\u001b[A\n",
      "Train logistic regression:  80%|██████████████████████████████████████████████████▍            | 16/20 [00:15<00:03,  1.13it/s, Loss=0.641, mae_loss=0.469]\u001b[A\n",
      "Train logistic regression:  85%|█████████████████████████████████████████████████████▌         | 17/20 [00:15<00:02,  1.13it/s, Loss=0.641, mae_loss=0.469]\u001b[A\n",
      "Train logistic regression:  85%|█████████████████████████████████████████████████████▌         | 17/20 [00:15<00:02,  1.13it/s, Loss=0.638, mae_loss=0.467]\u001b[A\n",
      "Train logistic regression:  90%|████████████████████████████████████████████████████████▋      | 18/20 [00:15<00:01,  1.13it/s, Loss=0.638, mae_loss=0.467]\u001b[A\n",
      "Train logistic regression:  90%|████████████████████████████████████████████████████████▋      | 18/20 [00:16<00:01,  1.13it/s, Loss=0.635, mae_loss=0.466]\u001b[A\n",
      "Train logistic regression:  95%|███████████████████████████████████████████████████████████▊   | 19/20 [00:16<00:00,  1.12it/s, Loss=0.635, mae_loss=0.466]\u001b[A\n",
      "Train logistic regression:  95%|███████████████████████████████████████████████████████████▊   | 19/20 [00:17<00:00,  1.12it/s, Loss=0.633, mae_loss=0.464]\u001b[A\n",
      "Train logistic regression: 100%|███████████████████████████████████████████████████████████████| 20/20 [00:17<00:00,  1.13it/s, Loss=0.633, mae_loss=0.464]\u001b[A\n",
      "E step:   0%|                                                                                                                        | 0/4 [00:17<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-01 02:06:44,005 INFO em_algo _validate Corr coef: {'kendall': 0.4729044299834083, 'spearman': 0.6381735298289565}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "M step:  25%|████████████████████████████                                                                                    | 1/4 [00:56<02:49, 56.58s/it]\n",
      "Train logistic regression:   0%|                                                                                                    | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Train logistic regression:   0%|                                                                        | 0/20 [00:00<?, ?it/s, Loss=0.607, mae_loss=0.452]\u001b[A\n",
      "Train logistic regression:   5%|███▏                                                            | 1/20 [00:00<00:15,  1.24it/s, Loss=0.607, mae_loss=0.452]\u001b[A\n",
      "Train logistic regression:   5%|███▏                                                            | 1/20 [00:01<00:15,  1.24it/s, Loss=0.594, mae_loss=0.445]\u001b[A\n",
      "Train logistic regression:  10%|██████▍                                                         | 2/20 [00:01<00:13,  1.30it/s, Loss=0.594, mae_loss=0.445]\u001b[A\n",
      "Train logistic regression:  10%|██████▍                                                         | 2/20 [00:02<00:13,  1.30it/s, Loss=0.581, mae_loss=0.438]\u001b[A\n",
      "Train logistic regression:  15%|█████████▌                                                      | 3/20 [00:02<00:12,  1.31it/s, Loss=0.581, mae_loss=0.438]\u001b[A\n",
      "Train logistic regression:  15%|█████████▊                                                       | 3/20 [00:03<00:12,  1.31it/s, Loss=0.568, mae_loss=0.43]\u001b[A\n",
      "Train logistic regression:  20%|█████████████                                                    | 4/20 [00:03<00:12,  1.32it/s, Loss=0.568, mae_loss=0.43]\u001b[A\n",
      "Train logistic regression:  20%|████████████▊                                                   | 4/20 [00:03<00:12,  1.32it/s, Loss=0.555, mae_loss=0.423]\u001b[A\n",
      "Train logistic regression:  25%|████████████████                                                | 5/20 [00:03<00:11,  1.31it/s, Loss=0.555, mae_loss=0.423]\u001b[A\n",
      "Train logistic regression:  25%|████████████████                                                | 5/20 [00:04<00:11,  1.31it/s, Loss=0.543, mae_loss=0.416]\u001b[A\n",
      "Train logistic regression:  30%|███████████████████▏                                            | 6/20 [00:04<00:10,  1.30it/s, Loss=0.543, mae_loss=0.416]\u001b[A\n",
      "Train logistic regression:  30%|███████████████████▌                                             | 6/20 [00:05<00:10,  1.30it/s, Loss=0.53, mae_loss=0.409]\u001b[A\n",
      "Train logistic regression:  35%|██████████████████████▊                                          | 7/20 [00:05<00:10,  1.29it/s, Loss=0.53, mae_loss=0.409]\u001b[A\n",
      "Train logistic regression:  35%|██████████████████████▍                                         | 7/20 [00:06<00:10,  1.29it/s, Loss=0.518, mae_loss=0.401]\u001b[A\n",
      "Train logistic regression:  40%|█████████████████████████▌                                      | 8/20 [00:06<00:09,  1.29it/s, Loss=0.518, mae_loss=0.401]\u001b[A\n",
      "Train logistic regression:  40%|█████████████████████████▌                                      | 8/20 [00:06<00:09,  1.29it/s, Loss=0.506, mae_loss=0.394]\u001b[A\n",
      "Train logistic regression:  45%|████████████████████████████▊                                   | 9/20 [00:06<00:08,  1.28it/s, Loss=0.506, mae_loss=0.394]\u001b[A\n",
      "Train logistic regression:  45%|████████████████████████████▊                                   | 9/20 [00:07<00:08,  1.28it/s, Loss=0.495, mae_loss=0.387]\u001b[A\n",
      "Train logistic regression:  50%|███████████████████████████████▌                               | 10/20 [00:07<00:07,  1.27it/s, Loss=0.495, mae_loss=0.387]\u001b[A\n",
      "Train logistic regression:  50%|████████████████████████████████                                | 10/20 [00:08<00:07,  1.27it/s, Loss=0.484, mae_loss=0.38]\u001b[A\n",
      "Train logistic regression:  55%|███████████████████████████████████▏                            | 11/20 [00:08<00:07,  1.23it/s, Loss=0.484, mae_loss=0.38]\u001b[A\n",
      "Train logistic regression:  55%|██████████████████████████████████▋                            | 11/20 [00:09<00:07,  1.23it/s, Loss=0.472, mae_loss=0.374]\u001b[A\n",
      "Train logistic regression:  60%|█████████████████████████████████████▊                         | 12/20 [00:09<00:06,  1.26it/s, Loss=0.472, mae_loss=0.374]\u001b[A\n",
      "Train logistic regression:  60%|█████████████████████████████████████▊                         | 12/20 [00:10<00:06,  1.26it/s, Loss=0.462, mae_loss=0.367]\u001b[A\n",
      "Train logistic regression:  65%|████████████████████████████████████████▉                      | 13/20 [00:10<00:05,  1.27it/s, Loss=0.462, mae_loss=0.367]\u001b[A\n",
      "Train logistic regression:  65%|█████████████████████████████████████████▌                      | 13/20 [00:10<00:05,  1.27it/s, Loss=0.451, mae_loss=0.36]\u001b[A\n",
      "Train logistic regression:  70%|████████████████████████████████████████████▊                   | 14/20 [00:10<00:04,  1.28it/s, Loss=0.451, mae_loss=0.36]\u001b[A\n",
      "Train logistic regression:  70%|████████████████████████████████████████████                   | 14/20 [00:11<00:04,  1.28it/s, Loss=0.441, mae_loss=0.353]\u001b[A\n",
      "Train logistic regression:  75%|███████████████████████████████████████████████▎               | 15/20 [00:11<00:03,  1.29it/s, Loss=0.441, mae_loss=0.353]\u001b[A\n",
      "Train logistic regression:  75%|███████████████████████████████████████████████▎               | 15/20 [00:12<00:03,  1.29it/s, Loss=0.431, mae_loss=0.347]\u001b[A\n",
      "Train logistic regression:  80%|██████████████████████████████████████████████████▍            | 16/20 [00:12<00:03,  1.30it/s, Loss=0.431, mae_loss=0.347]\u001b[A\n",
      "Train logistic regression:  80%|███████████████████████████████████████████████████▏            | 16/20 [00:13<00:03,  1.30it/s, Loss=0.421, mae_loss=0.34]\u001b[A\n",
      "Train logistic regression:  85%|██████████████████████████████████████████████████████▍         | 17/20 [00:13<00:02,  1.30it/s, Loss=0.421, mae_loss=0.34]\u001b[A\n",
      "Train logistic regression:  85%|█████████████████████████████████████████████████████▌         | 17/20 [00:13<00:02,  1.30it/s, Loss=0.411, mae_loss=0.334]\u001b[A\n",
      "Train logistic regression:  90%|████████████████████████████████████████████████████████▋      | 18/20 [00:14<00:01,  1.29it/s, Loss=0.411, mae_loss=0.334]\u001b[A\n",
      "Train logistic regression:  90%|████████████████████████████████████████████████████████▋      | 18/20 [00:14<00:01,  1.29it/s, Loss=0.402, mae_loss=0.328]\u001b[A\n",
      "Train logistic regression:  95%|███████████████████████████████████████████████████████████▊   | 19/20 [00:14<00:00,  1.29it/s, Loss=0.402, mae_loss=0.328]\u001b[A\n",
      "Train logistic regression:  95%|███████████████████████████████████████████████████████████▊   | 19/20 [00:15<00:00,  1.29it/s, Loss=0.393, mae_loss=0.322]\u001b[A\n",
      "Train logistic regression: 100%|███████████████████████████████████████████████████████████████| 20/20 [00:15<00:00,  1.29it/s, Loss=0.393, mae_loss=0.322]\u001b[A\n",
      "E step:  25%|████████████████████████████                                                                                    | 1/4 [01:12<02:49, 56.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-01 02:07:31,175 INFO em_algo _validate Corr coef: {'kendall': 0.06991115199760631, 'spearman': 0.09508559492601062}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "M step:  50%|████████████████████████████████████████████████████████                                                        | 2/4 [01:43<01:42, 51.05s/it]\n",
      "Train logistic regression:   0%|                                                                                                    | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Train logistic regression:   0%|                                                                        | 0/20 [00:00<?, ?it/s, Loss=0.524, mae_loss=0.405]\u001b[A\n",
      "Train logistic regression:   5%|███▏                                                            | 1/20 [00:00<00:14,  1.32it/s, Loss=0.524, mae_loss=0.405]\u001b[A\n",
      "Train logistic regression:   5%|███▏                                                            | 1/20 [00:01<00:14,  1.32it/s, Loss=0.512, mae_loss=0.398]\u001b[A\n",
      "Train logistic regression:  10%|██████▍                                                         | 2/20 [00:01<00:13,  1.32it/s, Loss=0.512, mae_loss=0.398]\u001b[A\n",
      "Train logistic regression:  10%|██████▌                                                           | 2/20 [00:02<00:13,  1.32it/s, Loss=0.5, mae_loss=0.391]\u001b[A\n",
      "Train logistic regression:  15%|█████████▉                                                        | 3/20 [00:02<00:12,  1.31it/s, Loss=0.5, mae_loss=0.391]\u001b[A\n",
      "Train logistic regression:  15%|█████████▌                                                      | 3/20 [00:03<00:12,  1.31it/s, Loss=0.488, mae_loss=0.383]\u001b[A\n",
      "Train logistic regression:  20%|████████████▊                                                   | 4/20 [00:03<00:12,  1.31it/s, Loss=0.488, mae_loss=0.383]\u001b[A\n",
      "Train logistic regression:  20%|████████████▊                                                   | 4/20 [00:03<00:12,  1.31it/s, Loss=0.477, mae_loss=0.376]\u001b[A\n",
      "Train logistic regression:  25%|████████████████                                                | 5/20 [00:03<00:11,  1.31it/s, Loss=0.477, mae_loss=0.376]\u001b[A\n",
      "Train logistic regression:  25%|████████████████                                                | 5/20 [00:04<00:11,  1.31it/s, Loss=0.466, mae_loss=0.369]\u001b[A\n",
      "Train logistic regression:  30%|███████████████████▏                                            | 6/20 [00:04<00:10,  1.32it/s, Loss=0.466, mae_loss=0.369]\u001b[A\n",
      "Train logistic regression:  30%|███████████████████▏                                            | 6/20 [00:05<00:10,  1.32it/s, Loss=0.455, mae_loss=0.362]\u001b[A\n",
      "Train logistic regression:  35%|██████████████████████▍                                         | 7/20 [00:05<00:09,  1.32it/s, Loss=0.455, mae_loss=0.362]\u001b[A\n",
      "Train logistic regression:  35%|██████████████████████▍                                         | 7/20 [00:06<00:09,  1.32it/s, Loss=0.444, mae_loss=0.356]\u001b[A\n",
      "Train logistic regression:  40%|█████████████████████████▌                                      | 8/20 [00:06<00:09,  1.30it/s, Loss=0.444, mae_loss=0.356]\u001b[A\n",
      "Train logistic regression:  40%|█████████████████████████▌                                      | 8/20 [00:06<00:09,  1.30it/s, Loss=0.434, mae_loss=0.349]\u001b[A\n",
      "Train logistic regression:  45%|████████████████████████████▊                                   | 9/20 [00:06<00:08,  1.29it/s, Loss=0.434, mae_loss=0.349]\u001b[A\n",
      "Train logistic regression:  45%|████████████████████████████▊                                   | 9/20 [00:07<00:08,  1.29it/s, Loss=0.423, mae_loss=0.342]\u001b[A\n",
      "Train logistic regression:  50%|███████████████████████████████▌                               | 10/20 [00:07<00:07,  1.29it/s, Loss=0.423, mae_loss=0.342]\u001b[A\n",
      "Train logistic regression:  50%|███████████████████████████████▌                               | 10/20 [00:08<00:07,  1.29it/s, Loss=0.413, mae_loss=0.336]\u001b[A\n",
      "Train logistic regression:  55%|██████████████████████████████████▋                            | 11/20 [00:08<00:06,  1.30it/s, Loss=0.413, mae_loss=0.336]\u001b[A\n",
      "Train logistic regression:  55%|██████████████████████████████████▋                            | 11/20 [00:09<00:06,  1.30it/s, Loss=0.404, mae_loss=0.329]\u001b[A\n",
      "Train logistic regression:  60%|█████████████████████████████████████▊                         | 12/20 [00:09<00:06,  1.30it/s, Loss=0.404, mae_loss=0.329]\u001b[A\n",
      "Train logistic regression:  60%|█████████████████████████████████████▊                         | 12/20 [00:09<00:06,  1.30it/s, Loss=0.394, mae_loss=0.323]\u001b[A\n",
      "Train logistic regression:  65%|████████████████████████████████████████▉                      | 13/20 [00:09<00:05,  1.30it/s, Loss=0.394, mae_loss=0.323]\u001b[A\n",
      "Train logistic regression:  65%|████████████████████████████████████████▉                      | 13/20 [00:10<00:05,  1.30it/s, Loss=0.385, mae_loss=0.316]\u001b[A\n",
      "Train logistic regression:  70%|████████████████████████████████████████████                   | 14/20 [00:10<00:04,  1.29it/s, Loss=0.385, mae_loss=0.316]\u001b[A\n",
      "Train logistic regression:  70%|████████████████████████████████████████████▊                   | 14/20 [00:11<00:04,  1.29it/s, Loss=0.376, mae_loss=0.31]\u001b[A\n",
      "Train logistic regression:  75%|████████████████████████████████████████████████                | 15/20 [00:11<00:03,  1.30it/s, Loss=0.376, mae_loss=0.31]\u001b[A\n",
      "Train logistic regression:  75%|███████████████████████████████████████████████▎               | 15/20 [00:12<00:03,  1.30it/s, Loss=0.367, mae_loss=0.304]\u001b[A\n",
      "Train logistic regression:  80%|██████████████████████████████████████████████████▍            | 16/20 [00:12<00:03,  1.31it/s, Loss=0.367, mae_loss=0.304]\u001b[A\n",
      "Train logistic regression:  80%|██████████████████████████████████████████████████▍            | 16/20 [00:13<00:03,  1.31it/s, Loss=0.358, mae_loss=0.298]\u001b[A\n",
      "Train logistic regression:  85%|█████████████████████████████████████████████████████▌         | 17/20 [00:13<00:02,  1.31it/s, Loss=0.358, mae_loss=0.298]\u001b[A\n",
      "Train logistic regression:  85%|██████████████████████████████████████████████████████▍         | 17/20 [00:13<00:02,  1.31it/s, Loss=0.35, mae_loss=0.292]\u001b[A\n",
      "Train logistic regression:  90%|█████████████████████████████████████████████████████████▌      | 18/20 [00:13<00:01,  1.31it/s, Loss=0.35, mae_loss=0.292]\u001b[A\n",
      "Train logistic regression:  90%|████████████████████████████████████████████████████████▋      | 18/20 [00:14<00:01,  1.31it/s, Loss=0.342, mae_loss=0.286]\u001b[A\n",
      "Train logistic regression:  95%|███████████████████████████████████████████████████████████▊   | 19/20 [00:14<00:00,  1.29it/s, Loss=0.342, mae_loss=0.286]\u001b[A\n",
      "Train logistic regression:  95%|███████████████████████████████████████████████████████████▊   | 19/20 [00:15<00:00,  1.29it/s, Loss=0.334, mae_loss=0.281]\u001b[A\n",
      "Train logistic regression: 100%|███████████████████████████████████████████████████████████████| 20/20 [00:15<00:00,  1.30it/s, Loss=0.334, mae_loss=0.281]\u001b[A\n",
      "E step:  50%|████████████████████████████████████████████████████████                                                        | 2/4 [01:59<01:42, 51.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-01 02:08:15,362 INFO em_algo _validate Corr coef: {'kendall': 0.09680817363794049, 'spearman': 0.13586935470521477}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "M step:  75%|████████████████████████████████████████████████████████████████████████████████████                            | 3/4 [02:27<00:47, 47.91s/it]\n",
      "Train logistic regression:   0%|                                                                                                    | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Train logistic regression:   0%|                                                                        | 0/20 [00:00<?, ?it/s, Loss=0.449, mae_loss=0.359]\u001b[A\n",
      "Train logistic regression:   5%|███▏                                                            | 1/20 [00:00<00:14,  1.30it/s, Loss=0.449, mae_loss=0.359]\u001b[A\n",
      "Train logistic regression:   5%|███▏                                                            | 1/20 [00:01<00:14,  1.30it/s, Loss=0.438, mae_loss=0.352]\u001b[A\n",
      "Train logistic regression:  10%|██████▍                                                         | 2/20 [00:01<00:13,  1.30it/s, Loss=0.438, mae_loss=0.352]\u001b[A\n",
      "Train logistic regression:  10%|██████▍                                                         | 2/20 [00:02<00:13,  1.30it/s, Loss=0.428, mae_loss=0.345]\u001b[A\n",
      "Train logistic regression:  15%|█████████▌                                                      | 3/20 [00:02<00:13,  1.29it/s, Loss=0.428, mae_loss=0.345]\u001b[A\n",
      "Train logistic regression:  15%|█████████▌                                                      | 3/20 [00:03<00:13,  1.29it/s, Loss=0.418, mae_loss=0.339]\u001b[A\n",
      "Train logistic regression:  20%|████████████▊                                                   | 4/20 [00:03<00:12,  1.30it/s, Loss=0.418, mae_loss=0.339]\u001b[A\n",
      "Train logistic regression:  20%|████████████▊                                                   | 4/20 [00:03<00:12,  1.30it/s, Loss=0.408, mae_loss=0.332]\u001b[A\n",
      "Train logistic regression:  25%|████████████████                                                | 5/20 [00:03<00:11,  1.31it/s, Loss=0.408, mae_loss=0.332]\u001b[A\n",
      "Train logistic regression:  25%|████████████████                                                | 5/20 [00:04<00:11,  1.31it/s, Loss=0.398, mae_loss=0.325]\u001b[A\n",
      "Train logistic regression:  30%|███████████████████▏                                            | 6/20 [00:04<00:10,  1.28it/s, Loss=0.398, mae_loss=0.325]\u001b[A\n",
      "Train logistic regression:  30%|███████████████████▏                                            | 6/20 [00:05<00:10,  1.28it/s, Loss=0.388, mae_loss=0.319]\u001b[A\n",
      "Train logistic regression:  35%|██████████████████████▍                                         | 7/20 [00:05<00:10,  1.29it/s, Loss=0.388, mae_loss=0.319]\u001b[A\n",
      "Train logistic regression:  35%|██████████████████████▍                                         | 7/20 [00:06<00:10,  1.29it/s, Loss=0.379, mae_loss=0.312]\u001b[A\n",
      "Train logistic regression:  40%|█████████████████████████▌                                      | 8/20 [00:06<00:09,  1.28it/s, Loss=0.379, mae_loss=0.312]\u001b[A\n",
      "Train logistic regression:  40%|██████████████████████████                                       | 8/20 [00:06<00:09,  1.28it/s, Loss=0.37, mae_loss=0.306]\u001b[A\n",
      "Train logistic regression:  45%|█████████████████████████████▎                                   | 9/20 [00:06<00:08,  1.30it/s, Loss=0.37, mae_loss=0.306]\u001b[A\n",
      "Train logistic regression:  45%|█████████████████████████████▋                                    | 9/20 [00:07<00:08,  1.30it/s, Loss=0.361, mae_loss=0.3]\u001b[A\n",
      "Train logistic regression:  50%|████████████████████████████████▌                                | 10/20 [00:07<00:07,  1.30it/s, Loss=0.361, mae_loss=0.3]\u001b[A\n",
      "Train logistic regression:  50%|███████████████████████████████▌                               | 10/20 [00:08<00:07,  1.30it/s, Loss=0.352, mae_loss=0.294]\u001b[A\n",
      "Train logistic regression:  55%|██████████████████████████████████▋                            | 11/20 [00:08<00:06,  1.31it/s, Loss=0.352, mae_loss=0.294]\u001b[A\n",
      "Train logistic regression:  55%|██████████████████████████████████▋                            | 11/20 [00:09<00:06,  1.31it/s, Loss=0.343, mae_loss=0.288]\u001b[A\n",
      "Train logistic regression:  60%|█████████████████████████████████████▊                         | 12/20 [00:09<00:06,  1.31it/s, Loss=0.343, mae_loss=0.288]\u001b[A\n",
      "Train logistic regression:  60%|█████████████████████████████████████▊                         | 12/20 [00:10<00:06,  1.31it/s, Loss=0.335, mae_loss=0.282]\u001b[A\n",
      "Train logistic regression:  65%|████████████████████████████████████████▉                      | 13/20 [00:10<00:05,  1.31it/s, Loss=0.335, mae_loss=0.282]\u001b[A\n",
      "Train logistic regression:  65%|████████████████████████████████████████▉                      | 13/20 [00:10<00:05,  1.31it/s, Loss=0.327, mae_loss=0.276]\u001b[A\n",
      "Train logistic regression:  70%|████████████████████████████████████████████                   | 14/20 [00:10<00:04,  1.28it/s, Loss=0.327, mae_loss=0.276]\u001b[A\n",
      "Train logistic regression:  70%|████████████████████████████████████████████▊                   | 14/20 [00:11<00:04,  1.28it/s, Loss=0.319, mae_loss=0.27]\u001b[A\n",
      "Train logistic regression:  75%|████████████████████████████████████████████████                | 15/20 [00:11<00:03,  1.28it/s, Loss=0.319, mae_loss=0.27]\u001b[A\n",
      "Train logistic regression:  75%|███████████████████████████████████████████████▎               | 15/20 [00:12<00:03,  1.28it/s, Loss=0.312, mae_loss=0.265]\u001b[A\n",
      "Train logistic regression:  80%|██████████████████████████████████████████████████▍            | 16/20 [00:12<00:03,  1.29it/s, Loss=0.312, mae_loss=0.265]\u001b[A\n",
      "Train logistic regression:  80%|██████████████████████████████████████████████████▍            | 16/20 [00:13<00:03,  1.29it/s, Loss=0.304, mae_loss=0.259]\u001b[A\n",
      "Train logistic regression:  85%|█████████████████████████████████████████████████████▌         | 17/20 [00:13<00:02,  1.29it/s, Loss=0.304, mae_loss=0.259]\u001b[A\n",
      "Train logistic regression:  85%|█████████████████████████████████████████████████████▌         | 17/20 [00:13<00:02,  1.29it/s, Loss=0.297, mae_loss=0.254]\u001b[A\n",
      "Train logistic regression:  90%|████████████████████████████████████████████████████████▋      | 18/20 [00:13<00:01,  1.31it/s, Loss=0.297, mae_loss=0.254]\u001b[A\n",
      "Train logistic regression:  90%|█████████████████████████████████████████████████████████▌      | 18/20 [00:14<00:01,  1.31it/s, Loss=0.29, mae_loss=0.249]\u001b[A\n",
      "Train logistic regression:  95%|████████████████████████████████████████████████████████████▊   | 19/20 [00:14<00:00,  1.31it/s, Loss=0.29, mae_loss=0.249]\u001b[A\n",
      "Train logistic regression:  95%|███████████████████████████████████████████████████████████▊   | 19/20 [00:15<00:00,  1.31it/s, Loss=0.283, mae_loss=0.243]\u001b[A\n",
      "Train logistic regression: 100%|███████████████████████████████████████████████████████████████| 20/20 [00:15<00:00,  1.29it/s, Loss=0.283, mae_loss=0.243]\u001b[A\n",
      "E step:  75%|████████████████████████████████████████████████████████████████████████████████████                            | 3/4 [02:43<00:47, 47.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-01 02:08:59,385 INFO em_algo _validate Corr coef: {'kendall': 0.03107423902439259, 'spearman': 0.041038934663484586}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E step: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [03:11<00:00, 47.99s/it]\n"
     ]
    }
   ],
   "source": [
    "em_model.fit(coo_features, target, players, skils_encoder, test_team_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:made-adv-ml2]",
   "language": "python",
   "name": "conda-env-made-adv-ml2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
