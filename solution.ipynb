{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alex9\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\parentpoller.py:110: UserWarning: Parent poll failed.  If the frontend dies,\n",
      "                the kernel may be left running.  Please let us know\n",
      "                about your system (bitness, Python, etc.) at\n",
      "                ipython-dev@scipy.org\n",
      "  warnings.warn(\"\"\"Parent poll failed.  If the frontend dies,\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn import pipeline\n",
    "from sklearn import linear_model\n",
    "from scipy import sparse, stats\n",
    "from tqdm import tqdm\n",
    "from itertools import repeat\n",
    "from numba import jit\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rating_model import TeamResults\n",
    "from rating_model import PICKLE_PROTOCOL\n",
    "from rating_model import EMRatingModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tours_datapath = pathlib.Path(\"data\", \"pickle_data\", \"tournaments-dt.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tours = pd.read_pickle(str(tours_datapath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_datapath = pathlib.Path(\"data\", \"pickle_data\", \"players-dt.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_info = pd.read_pickle(players_datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_res_datapath = pathlib.Path(\n",
    "    \"data\", \"team_res\", \"train_team_results.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(team_res_datapath, \"rb\") as dump_file:\n",
    "    team_res = pickle.load(dump_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_unknown_team_players = 0\n",
    "total_unknown_answers = 0\n",
    "for tour_id in team_res.tours:\n",
    "    for team_id in team_res[tour_id]:\n",
    "        team = team_res[tour_id][team_id]\n",
    "        if not team.members:\n",
    "            total_unknown_team_players += 1\n",
    "        if not team.mask:\n",
    "            total_unknown_answers += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество команд без состава команды: \n",
      "109\n",
      "Количество команд с неизвестными повопроснами результатами: \n",
      "173\n"
     ]
    }
   ],
   "source": [
    "print(\"Количество команд без состава команды: \", total_unknown_team_players,\n",
    "      \"Количество команд с неизвестными повопроснами результатами: \", total_unknown_answers, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1105 entries, 4628 to 6485\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype              \n",
      "---  ------        --------------  -----              \n",
      " 0   name          1105 non-null   object             \n",
      " 1   dateStart     1105 non-null   datetime64[ns, UTC]\n",
      " 2   dateEnd       1105 non-null   datetime64[ns, UTC]\n",
      " 3   type          1105 non-null   object             \n",
      " 4   season        1015 non-null   object             \n",
      " 5   orgcommittee  1105 non-null   object             \n",
      " 6   synchData     669 non-null    object             \n",
      " 7   questionQty   1105 non-null   object             \n",
      "dtypes: datetime64[ns, UTC](2), object(6)\n",
      "memory usage: 77.7+ KB\n"
     ]
    }
   ],
   "source": [
    "tours.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convert to dataframe: 100%|██████████████████████████████████████████████████████████| 682/682 [01:50<00:00,  6.16it/s]\n"
     ]
    }
   ],
   "source": [
    "players = team_res.to_player_dataframe(filter_by_mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert players.index.is_monotonic_increasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17949880 entries, 0 to 17949879\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Dtype\n",
      "---  ------           -----\n",
      " 0   tour_id          int64\n",
      " 1   team_id          int64\n",
      " 2   player_id        int64\n",
      " 3   answer_id        int64\n",
      " 4   is_right_answer  bool \n",
      "dtypes: bool(1), int64(4)\n",
      "memory usage: 564.9 MB\n"
     ]
    }
   ],
   "source": [
    "players.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tour_id</th>\n",
       "      <th>team_id</th>\n",
       "      <th>player_id</th>\n",
       "      <th>answer_id</th>\n",
       "      <th>is_right_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4772</td>\n",
       "      <td>45556</td>\n",
       "      <td>6212</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4772</td>\n",
       "      <td>45556</td>\n",
       "      <td>6212</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4772</td>\n",
       "      <td>45556</td>\n",
       "      <td>6212</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4772</td>\n",
       "      <td>45556</td>\n",
       "      <td>6212</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4772</td>\n",
       "      <td>45556</td>\n",
       "      <td>6212</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tour_id  team_id  player_id  answer_id  is_right_answer\n",
       "0     4772    45556       6212          0             True\n",
       "1     4772    45556       6212          1             True\n",
       "2     4772    45556       6212          2             True\n",
       "3     4772    45556       6212          3             True\n",
       "4     4772    45556       6212          4             True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = players[\"is_right_answer\"].astype(np.int8).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# players[\"tour_team_id\"] = (players[\"tour_id\"].astype(str) + \" \" + players[\"team_id\"].astype(str)).factorize()[0]\n",
    "# player_indices_in_team_by_round = []\n",
    "\n",
    "# for group, data in players.groupby(\"tour_team_id\"):\n",
    "#     player_indices_in_team_by_round.append(data.index.to_list())\n",
    "\n",
    "# max_length = len(max(player_indices_in_team_by_round, key=len))\n",
    "# # pad_index это фейковый индекс и нужен только для того чтобы использовать функцию np.take\n",
    "# # Значение по этому индексу всегда равно 0\n",
    "# PAD_INDEX = len(target)\n",
    "# for i in range(len(player_indices_in_team_by_round)):\n",
    "#     indices = player_indices_in_team_by_round[i]\n",
    "#     if len(indices) < max_length:\n",
    "#         zeroing_mask[indices] = 1\n",
    "#         player_indices_in_team_by_round[i].extend(repeat(PAD_INDEX, max_length - len(indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# players.drop(\"tour_team_id\", axis=\"columns\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# player_indices_in_team_by_round = np.array(player_indices_in_team_by_round)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Построение логистической регрессии для ранжирования игроков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    0.568645\n",
       "True     0.431355\n",
       "Name: is_right_answer, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players[\"is_right_answer\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dtype = np.float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "skils_encoder = preprocessing.OneHotEncoder(dtype=feature_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "skils_features = skils_encoder.fit_transform(\n",
    "    players[\"player_id\"].to_numpy().reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "questione_complex_encoder = preprocessing.OneHotEncoder(dtype=feature_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_complex = questione_complex_encoder.fit_transform(\n",
    "    players[\"answer_id\"].to_numpy().reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = sparse.hstack((skils_features, questions_complex))\n",
    "features = sparse.csr_matrix(features)\n",
    "del skils_features\n",
    "del questions_complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<17949880x91104 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 35899760 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_model_filepath = pathlib.Path(\"model\", \"log-reg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_model_filepath.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "force_train = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dump = dump_model_filepath / \"log-reg.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not force_train and model_dump.exists():\n",
    "    with open(model_dump, \"rb\") as dump_file:\n",
    "        regression = pickle.load(dump_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if regression is None:\n",
    "    regression = linear_model.LogisticRegression(\n",
    "        penalty=\"none\", verbose=2, max_iter=200)\n",
    "    regression.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(model_dump, \"wb\") as dump_file:\n",
    "    pickle.dump(regression,  dump_file, protocol=PICKLE_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rating(skill_encoder, coefs) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    all_players_ids = skill_encoder.categories_[0]\n",
    "    for player_id in all_players_ids:\n",
    "        rows.append({\"player_id\": player_id, \"skill\": coefs[np.where(\n",
    "            all_players_ids == player_id)[0][0]]})\n",
    "    return pd.DataFrame.from_records(rows, index=\"player_id\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "player_ratings = get_rating(skils_encoder, regression.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_ratings.sort_values(\"skill\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skill</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>player_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27403</th>\n",
       "      <td>4.053972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4270</th>\n",
       "      <td>3.904938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28751</th>\n",
       "      <td>3.768449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30260</th>\n",
       "      <td>3.658079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30152</th>\n",
       "      <td>3.650698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              skill\n",
       "player_id          \n",
       "27403      4.053972\n",
       "4270       3.904938\n",
       "28751      3.768449\n",
       "30260      3.658079\n",
       "30152      3.650698"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player_ratings.nlargest(5, \"skill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка результатов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для сравнение команд воспользуемся простым правилом. Для каждой команды в турнире возьмём игроков в отсортированном по убыванию силе игроков и отсортируем команды в лексикографическом порядке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_team_res_datapath = pathlib.Path(\n",
    "    \"data\", \"team_res\", \"test_team_results.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(test_team_res_datapath, \"rb\") as dump_file:\n",
    "    team_res_test = pickle.load(dump_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_team_ratings = team_res_test.to_team_rating_by_tour()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_team_ratings.dropna(axis=\"index\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 21914 entries, 0 to 22430\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   tour_id      21914 non-null  int64  \n",
      " 1   members      21914 non-null  object \n",
      " 2   team_id      21914 non-null  int64  \n",
      " 3   tour_rating  21914 non-null  float64\n",
      "dtypes: float64(1), int64(2), object(1)\n",
      "memory usage: 856.0+ KB\n"
     ]
    }
   ],
   "source": [
    "test_team_ratings.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_team_ratings.sort_values([\"tour_id\", \"tour_rating\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tour_id</th>\n",
       "      <th>members</th>\n",
       "      <th>team_id</th>\n",
       "      <th>tour_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4957</td>\n",
       "      <td>(30152, 30270, 27822, 28751, 27403, 4270)</td>\n",
       "      <td>49804</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4957</td>\n",
       "      <td>(34936, 40877, 25177, 113703, 33792, 107161)</td>\n",
       "      <td>4109</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4957</td>\n",
       "      <td>(33620, 21346, 13857, 46339, 37836, 19632)</td>\n",
       "      <td>3875</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4957</td>\n",
       "      <td>(32901, 28689, 19541, 13689, 9801, 18194)</td>\n",
       "      <td>77418</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4957</td>\n",
       "      <td>(6482, 34846, 36120, 32458, 25882, 30475)</td>\n",
       "      <td>2</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tour_id                                       members  team_id  tour_rating\n",
       "0     4957     (30152, 30270, 27822, 28751, 27403, 4270)    49804          1.0\n",
       "1     4957  (34936, 40877, 25177, 113703, 33792, 107161)     4109          2.0\n",
       "2     4957    (33620, 21346, 13857, 46339, 37836, 19632)     3875          3.0\n",
       "3     4957     (32901, 28689, 19541, 13689, 9801, 18194)    77418          4.0\n",
       "4     4957     (6482, 34846, 36120, 32458, 25882, 30475)        2          5.5"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_team_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def player2ratings(players_id, player_ratings):\n",
    "    ratings = []\n",
    "    for player_id in players_id:\n",
    "        try:\n",
    "            ratings.append(player_ratings.loc[player_id, \"skill\"])\n",
    "        except KeyError:\n",
    "            pass\n",
    "    ratings.sort(reverse=True)\n",
    "    return tuple(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_teams(teams, player_skills):\n",
    "    ranking_teams = teams.copy()\n",
    "    ranking_teams[\"player_skils\"] = ranking_teams[\"members\"].apply(\n",
    "        lambda x: player2ratings(x, player_skills))\n",
    "    ranking_teams.sort_values(\"player_skils\", ascending=False, inplace=True)\n",
    "    ranking_teams.drop(\"player_skils\", axis=\"columns\", inplace=True)\n",
    "    return ranking_teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_rank(team_res, player_ratings):\n",
    "    kendall_values = []\n",
    "    for tour_id, teams in team_res.groupby(\"tour_id\"):\n",
    "        new_teams = teams[[\"members\", \"tour_rating\"]].copy()\n",
    "        new_teams.reset_index(inplace=True)\n",
    "        original_order = new_teams.index.to_numpy()\n",
    "        new_teams = rank_teams(new_teams, player_ratings)\n",
    "        rank_order = new_teams.index.to_numpy()\n",
    "        kendall_values.append(stats.kendalltau(original_order, rank_order)[0])\n",
    "    return np.nanmean(kendall_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Коэффициент ранговой корреляции Кендалла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5752683352089869"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_rank(test_team_ratings, player_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_team_ratings\n",
    "del player_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EM алгоритм"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмртрим ответы команды на вопросы. Если команда $t$ ответила на вопрос $q$, то это означает, что хотя бы один игрок ответил на вопрос. Если команда не ответила на вопрос, то это означает, что ни один игрок также не оветил на вопрос.\n",
    "\n",
    "Таким образом введём скрытые переменные: $h_{i,q}$- игорок под номером $i$ ответил на вопрос $q$. Они связаны с $x_{t,q}$ следующим соотношением:\n",
    "$$\n",
    "x_{t,q} = \n",
    "\\begin{cases}\n",
    "0, \\text{ то } h_{i,q} = 0 \\text{ для всех игроков в команде } t,\\\\\n",
    "1, h_{i,q}=1 \\text{ для хотя бы одного игрока в команде } t. \n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Тогда веротяность $p\\left(h_{i,q} \\vert s_i, c_q\\right) \\sim \\sigma\\left(b + s_i + c_q\\right), s_i-$ сила игрока $i$, $c_q-$ сложность вопроса, $b \\in \\mathbb{R}-$ глобальное смещение. Условную веротяность будем моделировать с помощью сигмоиды."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим итерация EM-алгоритма для $m \\geq 0$.\n",
    "\n",
    "## E-шаг\n",
    "\n",
    "$$\n",
    "\\mathrm{M} \\left[ h^{(m+1)}_{i,q} \\right] = \n",
    "\\begin{cases}\n",
    "0, x_{t,q} = 0,\\\\\n",
    "p\\left( h^{(m)}_{i,q} = 1 \\vert \\exists j \\in t, h^{(m)}_{j,k} = 1\\right) =\n",
    "\\dfrac{\\sigma \\left(b^{(m)} + s^{(m)}_i + c^{(m)}_q\\right)}{1-\\prod\\limits_{k \\in t} \\left(1 - \\sigma\\left(b^{(m)} + s^{(m)}_k + c^{(m)}_q\\right)\\right)}, \\text{ если } x_{t,q} = 1.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "## М-шаг\n",
    "\n",
    "Происходит обучение обучение логистичексой регрессии при известных $\\mathrm{M} \\left[ h^{(m+1)}_{i,q} \\right]$ и уточнение параметров:\n",
    "$$\n",
    "\\mathrm{M} \\left[ h^{(m+1)}_{i,q} \\right] \\sim \\sigma\\left(b^{(m+1)} + s^{(m+1)}_k + c^{(m+1)}_q\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "Пусть параметры модели образуют составляют вектор $w = \\left(s_1,s_2,\\ldots,s_P, c_1, c_2, \\ldots, c_A, b \\right)^T,$ где $P-$ общее число игроков, $A-$ общее число вопросов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sigmoid(x):\n",
    "#     return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def update_hidden_values(hidden_variables, indices_player_in_one_team_by_round, predicted_proba, pad_index):\n",
    "#     predicted_proba_by_groups = np.take(predicted_proba, indices_player_in_one_team_by_round)\n",
    "#     predicted_proba_by_groups /= (1 - np.prod(1 - predicted_proba_by_groups, axis=1).reshape(-1, 1))\n",
    "    \n",
    "#     for i, index in enumerate(indices_player_in_one_team_by_round):\n",
    "#         not_fake_mask = index != pad_index\n",
    "#         not_fake_indices = index[not_fake_mask]\n",
    "#         hidden_variables[not_fake_indices] = predicted_proba_by_groups[i, not_fake_mask]\n",
    "    \n",
    "#     np.nan_to_num(hidden_variables, copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def expectation(hidden_variables, target, indices_player_in_one_team_by_round, features, w, b, pad_index):\n",
    "#     hidden_variables.fill(0)\n",
    "#     predicted_proba = (features @ w).astype(np.float32)\n",
    "#     predicted_proba += b\n",
    "#     # Add fake value for vectorizing idexing operations\n",
    "#     predicted_proba = np.append(predicted_proba, 0)\n",
    "#     update_hidden_values(hidden_variables, indices_player_in_one_team_by_round, predicted_proba, pad_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden_variables = np.zeros_like(target, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expectation(hidden_variables, target, player_indices_in_team_by_round, features, regression.coef_[0].astype(np.float32), regression.intercept_.astype(np.float32), PAD_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "coo_features = features.tocoo(copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<17949880x91104 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 35899760 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coo_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-29 01:25:57,393 INFO em_algo _build_player_team_round_indices Build indices masks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 86964/86964 [00:07<00:00, 11299.59it/s]\n"
     ]
    }
   ],
   "source": [
    "model = EMRatingModel(coo_features, target, players, 3, 1e-2, 10, torch.device(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EM algorithm:   0%|                                                                              | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-29 01:27:00,879 INFO em_algo _expectation Expectation step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EM algorithm:   0%|                                                                              | 0/3 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 548.00 MiB (GPU 0; 6.00 GiB total capacity; 4.18 GiB already allocated; 482.50 MiB free; 4.19 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-f781fe65eb00>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Work\\Other\\made\\module2\\made-adv-ml\\made-adv-ml2\\rating_model\\em_algo\\em_algo.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_em_num_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"EM algorithm\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m             \u001b[0mlog_regr_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_expectation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_regr_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maximization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AnacondaEnvs\\made-adv-ml2\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Work\\Other\\made\\module2\\made-adv-ml\\made-adv-ml2\\rating_model\\em_algo\\em_algo.py\u001b[0m in \u001b[0;36m_expectation\u001b[1;34m(self, regression_params, bias)\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_logger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Expectation step\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hidden_variables\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[0mpredicted_proba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_features\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mregression_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mpredicted_proba\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;31m# Add fake value for vectorizing idexing operations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 548.00 MiB (GPU 0; 6.00 GiB total capacity; 4.18 GiB already allocated; 482.50 MiB free; 4.19 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "model.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:made-adv-ml2]",
   "language": "python",
   "name": "conda-env-made-adv-ml2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
